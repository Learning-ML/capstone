spy_prc <- spy$SPY[,6]
ret_spy_daily <- diff(spy_prc)/lag(spy_prc)
ret_spy_div   <- spy$SPY.div/spy_prc
mean(ret_spy_daily, na.rm=T) * 252    # ~ 8.71%/year
mean(ret_spy_div,na.rm=T) * 4 # one dividend per quarter 1.80%/year
sp_avg20 = rollmean(sp_prc, 20, align='center')
plot(sp_avg20)
sp_avg100 = rollmean(sp_prc, 100, align='center')
plot(sp_avg100)
ret_sp500_daily<-ret_sp500_daily[2:length(ret_sp500_daily)]  # removing the first nan element
ret_sp500_avg20 = rollmean(ret_sp500_daily, 20, align='center')
plot(ret_sp500_avg20)
ret_sp500_avg100 = rollmean(ret_sp500_daily, 100, align='center')
plot(ret_sp500_avg100)       # The 100 trading days moving average is smoother than the 20 days version
qqnorm(ret_sp500_daily)
qqline(ret_sp500_daily)
N <- 100
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.2
X[1]  <- 0.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
plot(X,type='l')
N <- 100
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
Y <- numeric(N)
phi <- 0.6
Y[1]  <- 0.0
for (i in 2:N) {
Y[i] <- epsilon[i] + phi * epsilon[i-1]
}
plot(Y,type='l')
library(tseries)
install.packages('tseries')
library(tseries)
library(tseries)
install.packages('tseries')
library(tseries)
adf.test(sp_prc)
adf.test(sp_prc)
spy_prc <- spy$SPY[,6]
ret_spy_daily <- diff(spy_prc)/lag(spy_prc)
ret_spy_div   <- spy$SPY.div/spy_prc
mean(ret_spy_daily, na.rm=T) * 252    # ~ 8.71%/year
mean(ret_spy_div,na.rm=T) * 4 # one dividend per quarter 1.80%/year
sp_avg20 = rollmean(sp_prc, 20, align='center')
plot(sp_avg20)
sp_avg100 = rollmean(sp_prc, 100, align='center')
plot(sp_avg100)
ret_sp500_daily<-ret_sp500_daily[2:length(ret_sp500_daily)]  # removing the first nan element
ret_sp500_avg20 = rollmean(ret_sp500_daily, 20, align='center')
plot(ret_sp500_avg20)
ret_sp500_avg100 = rollmean(ret_sp500_daily, 100, align='center')
plot(ret_sp500_avg100)       # The 100 trading days moving average is smoother than the 20 days version
qqnorm(ret_sp500_daily)
qqline(ret_sp500_daily)
N <- 100
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.2
X[1]  <- 0.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
plot(X,type='l')
N <- 100
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
Y <- numeric(N)
phi <- 0.6
Y[1]  <- 0.0
for (i in 2:N) {
Y[i] <- epsilon[i] + phi * epsilon[i-1]
}
plot(Y,type='l')
library(tseries)
adf.test(sp_prc)
adf.test(ret_sp500_daily)
load("~/Downloads/NYCDSA/Lecture Notes/Week 9/Time Series Analysis/TimeSeries_RLectureCode/sp500.RData")
adf.test(sp_prc)
adf.test(sp_prc)
adf.test(ret_sp500_daily)
N <- 100
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.2
X[1]  <- 2.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
adf.test(X)
set.seed(0)
N <- 100
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.95
X[1]  <- 2.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
adf.test(X)
N <- 10000
set.seed(0)
N <- 10000
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.95
X[1]  <- 2.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
adf.test(X)
set.seed(0)
N <- 100
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.95
X[1]  <- 2.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
adf.test(X)
set.seed(0)
N <- 100
sigma <- 0.01
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.95
X[1]  <- 2.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
adf.test(X)
set.seed(0)
N <- 100
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.95
X[1]  <- 2.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
adf.test(X)
set.seed(0)
N <- 100
sigma <- 0.01
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.95
X[1]  <- 2.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
adf.test(X)
set.seed(0)
N <- 100
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.95
X[1]  <- 2.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
adf.test(X)
N <- 100
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.5
X[1]  <- 2.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
acf(X, lag.max=10)  # lag.max = 10 to plot only the 10 terms
N <- 1000
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.5
X[1]  <- 2.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
acf(X, lag.max=10)  # lag.max = 10 to plot only the 10 terms
acf(X, lag.max=10)  # The noise in the auto-correlation function reduces as N goes large
acf(ret_sp500_daily, lag.max=100)   # The stock index is generally efficient, there is no long term pattern
View(ret_sp500_daily)
sum(is.na(ret_spy_daily))
rm(is.na(ret_sp500_daily))
is.na(ret_sp500_daily)
is.na(ret_sp500_daily[ret_sp500_daily])
acf(ret_sp500_daily, lag.max=100)   # The stock index is generally efficient, there is no long term pattern
ret_sp500_daily <- na.omit(ret_sp500_daily)
acf(ret_sp500_daily, lag.max=100)   # The stock index is generally efficient, there is no long term pattern
result_theta<-rollapply(as.vector(ret_sp500_daily),width=100,FUN=acf,lag.max=1,
type='correlation',plot=FALSE, align='right')
M<-length(result_theta[,1])
thetas <- numeric(M)
for (i in 1:M) {
thetas[i] <- result_theta[i,]$acf[2]
}
thetas <- as.xts(thetas, order.by=index(sp500_vola_daily[100:(M+99)]))
plot(thetas)
sp500_vola_daily <-rollapply(ret_sp500_daily, width=100, FUN=sd)
plot(sp500_vola_daily)
return_vola_100 <- sp500_vola_daily[100:(M+99)]
return_vola     <- as.vector(return_vola_100)
return_autocorr <- as.vector(thetas)
return_daily_100    <- as.vector(rollmean(ret_sp500_daily, 100, align='right'))
plot(return_daily_100, return_vola)
plot(return_vola, return_autocorr)
plot(return_daily_100, return_vola)
plot(return_vola, return_autocorr)
plot(return_daily_100, type='l')
plot(return_vola_100, type='l')
adf.test(return_vola_100)  #likely to be stationary
install.packages('forecast')
library(forecast)
library(forecast)
auto.arima(return_vola_100)  # default kpss test rejects the null hypothesis of stationary time series
auto.arima(return_vola_100, test='adf')
auto.arima(return_vola_100)  # default kpss test rejects the null hypothesis of stationary time series
auto.arima(return_vola_100, test='adf')
sample <- seq(100, 14299, 100)
ret_vola_sampled <- return_vola_100[sample]
auto.arima(ret_vola_sampled, test='adf', trace=T)  #ARIMA(1,0,0) with non-zero mean
auto.arima(ret_vola_sampled, trace=T)  # ARIMA(1,1,1) by using the kpss test intead of adf test
auto.arima(ret_vola_sampled^2, test='adf', trace=T)   # Don't forget Box-Cox!
acf(ret_vola_sampled^2)
acf(ret_vola_sampled^2)
auto.arima(ret_vola_sampled^2, test='adf', trace=T)   # Don't forget Box-Cox!
acf(ret_vola_sampled^2)
N <- 1000
epsilon <- rnorm(N, 0, 0.1)
X <- numeric(N)
for (i in 3:N) {
X[i] <- 0.5 * X[i-2] + epsilon[i]
}
acf(X, lag.max=20)
pacf(X, lag.max=20)
acf(X, lag.max=20)
pacf(X, lag.max=20)
load("~/Downloads/NYCDSA/Project/Kaggle/Boosting.RData")
gbmFit <- train(price_doc ~ . - id,
data = train,
method = "gbm",
tuneGrid=expand.grid(
n.trees=seq(100, 150, length=2),
interaction.depth=3,
shrinkage=.1,
n.minobsinnode = 10
),
trControl = fitControl,
verbose = FALSE)
gbmFit <- train(price_doc ~ . - id,
data = train,
method = "gbm",
tuneGrid=expand.grid(
n.trees=seq(100, 150, length=2),
interaction.depth=3,
shrinkage=.1,
n.minobsinnode = 10
),
trControl = fitControl,
verbose = FALSE)
library(caret)
library(mboost)
gbmFit <- train(price_doc ~ . - id,
data = train,
method = "gbm",
tuneGrid=expand.grid(
n.trees=seq(100, 150, length=2),
interaction.depth=3,
shrinkage=.1,
n.minobsinnode = 10
),
trControl = fitControl,
verbose = FALSE)
gbmFit
gbmFit
View(train)
gbmImp
gbmFit
gbmFit2
gbmFit3
colnames(train)
names(train)
names(train)
load("~/Downloads/NYCDSA/Project/Kaggle/MLR.RData")
names(train)
View(train)
cv <- cv.lm(train, model.saturated, m=3)
library(car)
cv <- cv.lm(train, model.saturated, m=3)
library(DAAG)
o
cv <- cv.lm(train, model.saturated, m=3)
attr(cv, "ms")
attributes(cv)
attr(cv, "rmse")
attr(cv, "ms")
attr(cv, "ms")^0.5
names(temp4)
cv <- cv.lm(temp4, temp4_mlr, m=3)
cv <- cv.lm(temp4, temp4_mlr, m=3)
attr(cv, "ms")^0.5
temp4[1,30] <- 6
cv <- cv.lm(temp4, temp4_mlr, m=3)
levels(temp4$material)
temp4[1,30] <- 5
cv <- cv.lm(temp4, temp4_mlr, m=3)
attr(cv, "ms")^0.5
View(temp4)
cv <- cv.lm(temp, temp5_mlr, m=3)
attr(cv, "ms")^0.5
cv <- cv.lm(temp, temp6_mlr, m=3)
attr(cv, "ms")^0.5
names(temp5)
attr(cv, "ms")^0.5
cv <- cv.lm(train, temp7_mlr, m=3)
attr(cv, "ms")
cv
attr(cv, "ms")^0.5
cv <- cv.lm(train, temp8_mlr, m=3)
attr(cv, "ms")^0.5
temp8_mlr
temp8_mlr$coefficients
temp8_mlr$terms
summary(temp8_mlr)
attr(cv, "ms")^0.5
cv <- cv.lm(train, temp8_mlr, m=3)
attr(cv, "ms")^0.5
library(HSAUR)
heptathlon
install.packages('HSAUR')
library(HSAUR)
heptathlon
plot(heptathlon)
library(car)
n<-names(data.frame(heptathlon))
f<-as.formula(paste("~", paste(n[!n %in% "score"],collapse = "+")))
f
scatterplotMatrix(f,data=heptathlon)
heptathlon.new = heptathlon
heptathlon.new$hurdles = max(heptathlon$hurdles) - heptathlon$hurdles
heptathlon.new$run200m = max(heptathlon$run200m) - heptathlon$run200m
heptathlon.new$run800m = max(heptathlon$run800m) - heptathlon$run800m
heptathlon.new
plot(heptathlon.new)
cor(heptathlon.new)
round(cor(heptathlon.new[,-8]), 2)
plot(heptathlon.new)
cor(heptathlon.new)
round(cor(heptathlon.new[,-8]), 2)
n<-names(data.frame(heptathlon.new))
f<-as.formula(paste("~", paste(n[!n %in% "score"],collapse = "+")))
f
scatterplotMatrix(f,data=heptathlon.new)
library(psych)
fa.parallel(heptathlon.new[, -8], fa = "pc", n.iter = 100)
abline(h = 1)
pc_heptathlon = principal(heptathlon.new[, -8], nfactors = 2, rotate = "none")
pc_heptathlon
biplot(pc_heptathlon)
factor.plot(pc_heptathlon, labels = colnames(heptathlon.new))
plot(pc_heptathlon$scores, type = "n") # type="n" does not produce any points or lines
text(pc_heptathlon$scores, rownames(heptathlon.new), cex = .75)
round(scale(heptathlon.new), 3)
round(heptathlon.new, 3)
load("~/Downloads/NYCDSA/Project/Kaggle/Boosting.RData")
gbmImp <- varImp(gbmFit, scale = TRUE)
gbmImp
View(train)
gbmFit
View(train)
gbmFit <- train(price_doc ~ . -id,
data = train,
method = "gbm",
tuneGrid=expand.grid(
n.trees= c(50, 100, 150),
interaction.depth=c(3, 5, 7),
shrinkage= c(.01, .1, .5, 1),
n.minobsinnode = c(5, 10, 15)
),
trControl = fitControl,
verbose = FALSE)
gbmFit
setwd("~/Downloads/NYCDSA/Project/Capstone/ameco/CSV")
df1  <- read.csv("AMECO1.TXT", header = TRUE, sep = ';')  # Population and Employment
setwd("~/Downloads/NYCDSA/Project/Capstone/ameco/TXT")
df1  <- read.csv("AMECO1.TXT", header = TRUE, sep = ';')  # Population and Employment
View(df1)
library(tidyr)
dim(df1)
df1_tidy <- gather(df1, key="year", value="value", 6:65)
View(df1_tidy)
View(df1_tidy)
View(df1_tidy)
df1_tidy <- spread(df1, key=SUB.CHAPTER, value=value)
df1_tidy <- spread(df1, key=SUB.CHAPTER, value='value')
View(df1_tidy)
df1_tidy <- spread(df1, key=SUB.CHAPTER, value=value)
df1_tidy1 <- spread(df1_tidy, key=SUB.CHAPTER, value="value")
View(df1_tidy1)
df1_tidy1 <- spread(df1_tidy, key=TITLE, value="value")
View(df1_tidy1)
spaindf = df1_tidy1 %>% filter(COUNTRY=='Spain')
library(dplyr)
spaindf = df1_tidy1 %>% filter(COUNTRY=='Spain')
View(spaindf)
unique(spaindf$UNIT)
################################################################
################################################################
################### Loading the data frames ####################
################################################################
################################################################
df1  <- read.csv("AMECO1.TXT", header = TRUE, sep = ';')  # Population and Employment
df2  <- read.csv("AMECO2.TXT", header = TRUE, sep = ';')  # Consumption
df3  <- read.csv("AMECO3.TXT", header = TRUE, sep = ';')  # Capital Formation and Saving, Total Economy And Sectors
df4  <- read.csv("AMECO4.TXT", header = TRUE, sep = ';')  # Domestic and Final Demand
df5  <- read.csv("AMECO5.TXT", header = TRUE, sep = ';')  # National Income
df6  <- read.csv("AMECO6.TXT", header = TRUE, sep = ';')  # Domestic Product
df7  <- read.csv("AMECO7.TXT", header = TRUE, sep = ';')  # Gross Domestic Product (Income Approach), Labour Costs
df8  <- read.csv("AMECO8.TXT", header = TRUE, sep = ';')  # Capital Stock
df9  <- read.csv("AMECO9.TXT", header = TRUE, sep = ';')  # Exports and Imports of Goods And Services, National Accounts
df10 <- read.csv("AMECO10.TXT", header = TRUE, sep = ';') # Balances with the Rest Of The World, National Accounts
df11 <- read.csv("AMECO11.TXT", header = TRUE, sep = ';') # Foreign Trade
df12 <- read.csv("AMECO12.TXT", header = TRUE, sep = ';') # National Accounts by Branch Of Activity
df13 <- read.csv("AMECO13.TXT", header = TRUE, sep = ';') # Monetary Variables
df14 <- read.csv("AMECO14.TXT", header = TRUE, sep = ';') # Corporations (S11 + S12)
df15 <- read.csv("AMECO15.TXT", header = TRUE, sep = ';') # Households and Npish (S14 + S15)
df16 <- read.csv("AMECO16.TXT", header = TRUE, sep = ';') # General Government (S13)
df17 <- read.csv("AMECO17.TXT", header = TRUE, sep = ';') # Cyclical Adjustment of Public Finance Variables
df18 <- read.csv("AMECO18.TXT", header = TRUE, sep = ';') # Gross Public Debt
write.csv(df1 , file = "AMECO1.csv")
write.csv(df2 , file = "AMECO2.csv")
write.csv(df3 , file = "AMECO3.csv")
write.csv(df4 , file = "AMECO4.csv")
write.csv(df5 , file = "AMECO5.csv")
write.csv(df6 , file = "AMECO6.csv")
write.csv(df7 , file = "AMECO7.csv")
write.csv(df8 , file = "AMECO8.csv")
write.csv(df9 , file = "AMECO9.csv")
write.csv(df10, file = "AMECO10.csv")
write.csv(df11, file = "AMECO11.csv")
write.csv(df12, file = "AMECO12.csv")
write.csv(df13, file = "AMECO13.csv")
write.csv(df14, file = "AMECO14.csv")
write.csv(df15, file = "AMECO15.csv")
write.csv(df16, file = "AMECO16.csv")
write.csv(df17, file = "AMECO17.csv")
write.csv(df18, file = "AMECO18.csv")
View(df1)
unique(df1$TITLE)
unique(df2$TITLE)
unique(df3$TITLE)
unique(df4$TITLE)
unique(df5$TITLE)
unique(df6$TITLE)
unique(df7$TITLE)
unique(df8$TITLE)
unique(df9$TITLE)
unique(df10$TITLE)
unique(df11$TITLE)
unique(df12$TITLE)
unique(df13$TITLE)
unique(df14$TITLE)
unique(df15$TITLE)
unique(df16$TITLE)
unique(df17$TITLE)
unique(df18$TITLE)
unique(df1$TITLE)
unique(df18$TITLE)
View(df1)
View(df2)
View(df5)
unique(df1$UNIT)
unique(df5$UNIT)
df_all <- rbind(d1, d2)
df_all <- rbind(df1, df2)
View(df_all)
df_all <- rbind(df1,
df2,
df3,
df4,
df5,
df6,
df7,
df8,
df9,
df10,
df11,
df12,
df13,
df14,
df15,
df16,
df17,
df18)
View(df_all)
save.image("~/Downloads/NYCDSA/Project/Capstone/ameco/data_import.RData")
